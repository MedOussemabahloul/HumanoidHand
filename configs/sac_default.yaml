env_name: HumanoidManip-v0
seed: 42
total_timesteps: 2000        # Nombre de pas d'entraînement (mets plus quand tu voudras un vrai apprentissage)
eval_interval: 1000
save_interval: 1000
buffer_size: 10000           # Taille du buffer de replay
batch_size: 32
gamma: 0.99                  # Discount factor
tau: 0.005                   # Soft update coefficient
lr: 0.0003                   # Learning rate
alpha: 0.2                   # Entropy regularization
hidden_sizes: [64, 64]       # Architecture du réseau de policy/Q-value
